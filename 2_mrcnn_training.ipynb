{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4xFO5HgN5Mhp"},"outputs":[],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"markdown","metadata":{"id":"TJlU0Ocu-EhW"},"source":["# 1.0 Install Mask RCNN library"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":731},"executionInfo":{"elapsed":19838,"status":"ok","timestamp":1593015117036,"user":{"displayName":"Colin U","photoUrl":"","userId":"09989661477393915736"},"user_tz":-60},"id":"YFJAezmMCOMU","outputId":"ff3ddc59-a5dd-4ad4-bb52-86fc0b45d9c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/ObjectRecognition/Mask_RCNN\n","WARNING:root:Fail load requirements file, so using default ones.\n","running install\n","running bdist_egg\n","running egg_info\n","writing mask_rcnn.egg-info/PKG-INFO\n","writing dependency_links to mask_rcnn.egg-info/dependency_links.txt\n","writing top-level names to mask_rcnn.egg-info/top_level.txt\n","reading manifest template 'MANIFEST.in'\n","writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_py\n","creating build/bdist.linux-x86_64/egg\n","creating build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/config.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/__init__.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/model.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/utils.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/parallel_model.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/visualize.py -> build/bdist.linux-x86_64/egg/mrcnn\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/config.py to config.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/model.py to model.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/utils.py to utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/parallel_model.py to parallel_model.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/visualize.py to visualize.cpython-36.pyc\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","copying mask_rcnn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying mask_rcnn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying mask_rcnn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying mask_rcnn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","zip_safe flag not set; analyzing archive contents...\n","creating 'dist/mask_rcnn-2.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing mask_rcnn-2.1-py3.6.egg\n","Copying mask_rcnn-2.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n","Adding mask-rcnn 2.1 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg\n","Processing dependencies for mask-rcnn==2.1\n","Finished processing dependencies for mask-rcnn==2.1\n"]}],"source":["%cd /content/drive/My Drive/Colab Notebooks/HD_object_recognition/Mask_RCNN\n","!python setup.py install"]},{"cell_type":"markdown","metadata":{"id":"KoAN8OsyWLrn"},"source":["# 1.1 Install compatible version of tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"elapsed":4801,"status":"ok","timestamp":1593015125056,"user":{"displayName":"Colin U","photoUrl":"","userId":"09989661477393915736"},"user_tz":-60},"id":"PDwk_0zooutg","outputId":"e6246787-9d05-4b71-b8fb-4b15368f674f"},"outputs":[{"name":"stdout","output_type":"stream","text":["TensorFlow 1.x selected.\n","1.15.2\n"]}],"source":["#!pip install tensorflow==1.14\n","%tensorflow_version 1.x\n","import tensorflow\n","print(tensorflow.__version__)\n","\n","tensorflow.compat.v1.logging.set_verbosity(tensorflow.compat.v1.logging.ERROR)"]},{"cell_type":"markdown","metadata":{"id":"SXnP2WtbJ05D"},"source":["# 1.2 Load data into an MRCNN Dataset() class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d9huEDRq5ufN"},"outputs":[],"source":["from os import listdir\n","from xml.etree import ElementTree\n","from numpy import zeros\n","from numpy import asarray\n","from mrcnn.utils import Dataset\n","from mrcnn.config import Config\n","from mrcnn.model import MaskRCNN\n","\n","\n","class SkinDataset(Dataset):\n","\n","\tdef load_dataset(self, dataset_dir, is_train=True):\n","\t\t# define features\n","\t\tself.add_class(\"dataset\", 1, \"follicular_bump\")\n","\t\tself.add_class(\"dataset\", 2, \"pre_erupted\")\n","\t\t# define data locations\n","\t\timages_dir = dataset_dir + '/training images/'\n","\t\tannotations_dir = dataset_dir + '/training annots/'\n","\t\t# find all images\n","\t\tfor filename in listdir(images_dir):\n","\t\t\timage_id = filename[0:-4]\n","\t\t\tlast_dig = filename[4:-4]\n","\t\t\tif image_id in ['']:\n","\t\t\t\tcontinue\n","\t\t\t# separate 20% of data for validation set\n","\t\t\tif is_train and int(last_dig) in [1, 6]:\n","\t\t\t\tcontinue\n","\t\t\tif not is_train and int(last_dig) not in [1, 6]:\n","\t\t\t\tcontinue\n","\t\t\timg_path = images_dir + filename\n","\t\t\tann_path = annotations_dir + image_id + '.xml'\n","\t\t\t# add to dataset\n","\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path, class_ids = [0,1,2])\n","\n","\tdef extract_boxes(self, filename):\n","\t\t# load and parse the file\n","\t\ttree = ElementTree.parse(filename)\n","\t\troot = tree.getroot()\n","\t\t# extract each bounding box\n","\t\tboxes = list()\n","\t\tfor box in root.findall('.//object'):\n","\t\t\tname = box.find('name').text\n","\t\t\t## if name == 'follicular_bump':\n","\t\t\txmin = int(box.find('./bndbox/xmin').text)\n","\t\t\tymin = int(box.find('./bndbox/ymin').text)\n","\t\t\txmax = int(box.find('./bndbox/xmax').text)\n","\t\t\tymax = int(box.find('./bndbox/ymax').text)\n","\t\t\tcoors = [xmin, ymin, xmax, ymax, name]\n","\t\t\tboxes.append(coors)\n","\t\t# extract image dimensions\n","\t\twidth = int(root.find('.//size/width').text)\n","\t\theight = int(root.find('.//size/height').text)\n","\t\treturn boxes, width, height\n","\n","\tdef load_mask(self, image_id):\n","\t\t# get details of image\n","\t\tinfo = self.image_info[image_id]\n","\t\t# define box file location\n","\t\tpath = info['annotation']\n","\t\t# load XML\n","\t\tboxes, w, h = self.extract_boxes(path)\n","\t\t# create one array for all masks, each on a different channel\n","\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n","\t\t# create masks\n","\t\tclass_ids = list()\n","\t\tfor i in range(len(boxes)):\n","\t\t\tbox = boxes[i]\n","\t\t\trow_s, row_e = box[1], box[3]\n","\t\t\tcol_s, col_e = box[0], box[2]\n","\t\t\tif (box[4] == 'follicular_bump'):\n","\t\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n","\t\t\t\tclass_ids.append(self.class_names.index('follicular_bump'))\n","\t\t\telse:\n","\t\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 2\n","\t\t\t\tclass_ids.append(self.class_names.index('pre_erupted'))\n","\t\treturn masks, asarray(class_ids, dtype='int32')\n","\n","\t# load an image reference\n","\tdef image_reference(self, image_id):\n","\t\tinfo = self.image_info[image_id]\n","\t\treturn info['path']\n","\n","\n","# prepare training set\n","train_set = SkinDataset()\n","train_set.load_dataset('skin data', is_train=True)\n","train_set.prepare()\n","print('Train: %d' % len(train_set.image_ids))\n","\n","# prepare test set\n","test_set = SkinDataset()\n","test_set.load_dataset('skin data', is_train=False)\n","test_set.prepare()\n","print('Test: %d' % len(test_set.image_ids))\n"]},{"cell_type":"markdown","metadata":{"id":"mWarVoqmhut1"},"source":["# 1.3 Display an image with a bounding box"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MQDqhZJXgTO0"},"outputs":[],"source":["from matplotlib import pyplot\n","\n","IMAGE_ID = 1\n","OBJECT_ID = 0\n","\n","# load image and mask\n","image = train_set.load_image(IMAGE_ID)\n","mask, class_ids = train_set.load_mask(IMAGE_ID)\n","print('image shape: ', image.shape)\n","print('mask shape:  ', mask.shape)\n","\n","# plot image and mask\n","pyplot.figure(figsize=(15,10))\n","pyplot.imshow(image)\n","pyplot.imshow(mask[:, :, OBJECT_ID], cmap='gray', alpha=0.33)\n","pyplot.show()"]},{"cell_type":"markdown","metadata":{"id":"z1kKfexqh69Q"},"source":["# 1.4 Display an image with masks"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"executionInfo":{"elapsed":7,"status":"error","timestamp":1697817013414,"user":{"displayName":"Colin Urwin","userId":"09989661477393915736"},"user_tz":-60},"id":"-0ZEiDCZeRhi","outputId":"3389865c-74a7-449e-84c0-70b56535bf56"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d181951eace2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay_instances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextract_bboxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mIMAGE_ID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mrcnn'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}],"source":["from mrcnn.utils import Dataset\n","from mrcnn.visualize import display_instances\n","from mrcnn.utils import extract_bboxes\n","\n","IMAGE_ID = 1\n","\n","# load the image, masks and class ids\n","image = train_set.load_image(IMAGE_ID)\n","mask, class_ids = train_set.load_mask(IMAGE_ID)\n","\n","# extract bounding boxes from the masks\n","bbox = extract_bboxes(mask)\n","\n","# display image with masks and bounding boxes\n","display_instances(image, bbox, mask, class_ids, train_set.class_names)"]},{"cell_type":"markdown","metadata":{"id":"B-a8OUU8Vbcf"},"source":["# 1.5  Retrain MRCNN fitted on MSCOCO dataset with skin dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"32hmogclVS2M"},"outputs":[],"source":["class SkinConfig(Config):\n","\tNAME = \"skin11cfg\"\n","\tNUM_CLASSES = 3         # include background (class 0)\n","\tEPOCHS = 10\n","\tSTEPS_PER_EPOCH = 1159\n","\tVALIDATION_STEPS = 290\n","\tIMAGE_RESIZE_MODE = 'square'\n","\tIMAGE_MIN_DIM = 1472\n","\tIMAGE_MAX_DIM = 1728    # should be divisible by 64\n","\tIMAGES_PER_GPU = 1\n","\tLEARNING_RATE = 0.001   # 0.001\n","\n","# prepare config\n","config = SkinConfig()\n","config.display()\n","\n","# define the model\n","model = MaskRCNN(mode='training', model_dir='./', config=config)\n","model.keras_model.metrics_tensors = []\n","\n","# load weights (originally from MSCOCO model, but here retrained several times)\n","model.load_weights('/content/drive/My Drive/Colab Notebooks/HD_object_recognition/Mask_RCNN/models/best_so_far.h5', by_name=True) #, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n","\n","# train weights (output layers or 'heads')\n","model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=EPOCHS, layers='2+')\n","\n","## model.train(, layers='heads')  # Train head branches\n","## model.train(, layers='3+')     # Train resnet stage 3 and up\n","## model.train(, layers='4+')     # Train resnet stage 4 and up\n","## model.train(, layers='all')    # Train all layers"]},{"cell_type":"markdown","metadata":{"id":"EX8amXfRmLFM"},"source":["# 2.0 Select a saved model and evaluate Mean Average Precision"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cfoKfqZ-UqAd"},"outputs":[],"source":["saved_model_file = '/content/drive/My Drive/Colab Notebooks/HD_object_recognition/Mask_RCNN/models/best_so_far.h5'\n","\n","from os import listdir\n","from xml.etree import ElementTree\n","from numpy import zeros\n","from numpy import asarray\n","from numpy import expand_dims\n","from numpy import mean\n","from mrcnn.config import Config\n","from mrcnn.model import MaskRCNN\n","from mrcnn.utils import Dataset\n","from mrcnn.utils import compute_ap\n","from mrcnn.model import load_image_gt\n","from mrcnn.model import mold_image\n","\n","\n","class SkinDataset(Dataset):\n","\n","\tdef load_dataset(self, dataset_dir, is_train=True):\n","\t\t# define one class\n","\t\tself.add_class(\"dataset\", 1, \"follicular_bump\")\n","\t\tself.add_class(\"dataset\", 2, \"pre_erupted\")\n","\t\t# define data locations\n","\t\timages_dir = dataset_dir + '/validation images/'\n","\t\tannotations_dir = dataset_dir + '/validation annots/'\n","\t\t# find all images\n","\t\tfor filename in listdir(images_dir):\n","\t\t\t# extract image id\n","\t\t\timage_id = filename[:-4]\n","\t\t\t# skip bad images\n","\t\t\tif image_id in ['']:\n","\t\t\t\tcontinue\n","\t\t\t# skip all images after 35 if we are building the train set\n","\t\t\tif is_train and int(image_id) >= 35:\n","\t\t\t\tcontinue\n","\t\t\t# skip all images before 35 if we are building the test/val set\n","\t\t\tif not is_train and int(image_id) < 35:\n","\t\t\t\tcontinue\n","\t\t\timg_path = images_dir + filename\n","\t\t\tann_path = annotations_dir + image_id + '.xml'\n","\t\t\t# add to dataset\n","\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path, class_ids = [0,1,2])\n","\n","\tdef extract_boxes(self, filename):\n","\t\t# load and parse the file\n","\t\ttree = ElementTree.parse(filename)\n","\t\t# get the root of the document\n","\t\troot = tree.getroot()\n","\t\t# extract each bounding box\n","\t\tboxes = list()\n","\t\tfor box in root.findall('.//object'):\n","\t\t\tname = box.find('name').text\n","\t\t\txmin = int(box.find('./bndbox/xmin').text)\n","\t\t\tymin = int(box.find('./bndbox/ymin').text)\n","\t\t\txmax = int(box.find('./bndbox/xmax').text)\n","\t\t\tymax = int(box.find('./bndbox/ymax').text)\n","\t\t\tcoors = [xmin, ymin, xmax, ymax, name]\n","\t\t\tboxes.append(coors)\n","\t\t# extract image dimensions\n","\t\twidth = int(root.find('.//size/width').text)\n","\t\theight = int(root.find('.//size/height').text)\n","\t\treturn boxes, width, height\n","\n","\tdef load_mask(self, image_id):\n","\t\t# get details of image\n","\t\tinfo = self.image_info[image_id]\n","\t\t# define box file location\n","\t\tpath = info['annotation']\n","\t\t# load XML\n","\t\tboxes, w, h = self.extract_boxes(path)\n","\t\t# create one array for all masks, each on a different channel\n","\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n","\t\t# create masks\n","\t\tclass_ids = list()\n","\t\tfor i in range(len(boxes)):\n","\t\t\tbox = boxes[i]\n","\t\t\trow_s, row_e = box[1], box[3]\n","\t\t\tcol_s, col_e = box[0], box[2]\n","\t\t\tif (box[4] == 'pre_erupted'):\n","\t\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 2\n","\t\t\t\tclass_ids.append(self.class_names.index('pre_erupted'))\n","\t\t\telse:\n","\t\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n","\t\t\t\tclass_ids.append(self.class_names.index('follicular_bump'))\n","\t\treturn masks, asarray(class_ids, dtype='int32')\n","\n","\t# load an image reference\n","\tdef image_reference(self, image_id):\n","\t\tinfo = self.image_info[image_id]\n","\t\treturn info['path']\n","\n","\n","# define a configuration for the model\n","class PredictionConfig(Config):\n","\tNAME = \"skinX1.cfg\"\n","\tNUM_CLASSES = 3         ## include background (class 0)\n","\tSTEPS_PER_EPOCH = 36\n","\tVALIDATION_STEPS = 1\n","\tIMAGE_RESIZE_MODE = 'square'\n","\tIMAGE_MIN_DIM = 1472\n","\tIMAGE_MAX_DIM = 1728    ## should be divisible by 64\n","\tIMAGES_PER_GPU = 1\n","\tLEARNING_RATE = 0.001   ## 0.001\n","\n","\n","# calculate the mAP for a model on a given dataset\n","def evaluate_model(dataset, model, cfg):\n","\tAPs = list()\n","\tfor image_id in dataset.image_ids:\n","\t\t# load image, bounding boxes and masks for the image id\n","\t\timage, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n","\t\t# convert pixel values (e.g. center)\n","\t\tscaled_image = mold_image(image, cfg)\n","\t\t# convert image into one sample\n","\t\tsample = expand_dims(scaled_image, 0)\n","\t\t# make prediction\n","\t\tyhat = model.detect(sample, verbose=0)\n","\t\t# extract results for first sample\n","\t\tr = yhat[0]\n","\t\t# calculate statistics, including AP\n","\t\tAP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n","\t\t# store\n","\t\tAPs.append(AP)\n","\t# calculate the mean AP across all images\n","\tmAP = mean(APs)\n","\treturn mAP\n","\n","\n","# load the train dataset\n","train_set = SkinDataset()\n","train_set.load_dataset('skin data', is_train=True)\n","train_set.prepare()\n","print('Train: %d' % len(train_set.image_ids))\n","\n","# load the test dataset\n","test_set = SkinDataset()\n","test_set.load_dataset('skin data', is_train=False)\n","test_set.prepare()\n","print('Test: %d' % len(test_set.image_ids))\n","\n","# create config\n","cfg = PredictionConfig()\n","\n","# define the model and set to inference mode\n","model = MaskRCNN(mode='inference', model_dir='./', config=cfg)\n","model.keras_model.metrics_tensors = []\n","\n","# load model weights\n","model.load_weights(saved_model_file, by_name=True)\n","\n","# evaluate model on training dataset\n","train_mAP = evaluate_model(train_set, model, cfg)\n","print(\"Train mAP: %.3f\" % train_mAP)\n","\n","# evaluate model on test dataset\n","test_mAP = evaluate_model(test_set, model, cfg)\n","print(\"Test mAP: %.3f\" % test_mAP)\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM3ZQgy/Oe9PbT0fTZQG2eG","mount_file_id":"1SrOMPNrTPfEn01tbHymJA9z-x5IPSFfR","provenance":[{"file_id":"1STesJQwn-sYah87TYKTDQ18BL4Dq_JI_","timestamp":1591217957671},{"file_id":"1c1xTKIkIcD6ITYFqV2orgh_NNxGM1dkf","timestamp":1590175254786}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
